def tsv2subjectinfo(events_file, confounds_file=None, exclude=None, trim_indices=None):
    """
    Function to go from events tsv + confounds tsv to subjectinfo,
    which can then be passed to model setup functions.

    events_file, confounds_file: paths to these things
    exclude: trial_types in the events_file to be ignored (does not apply to confounds)
    trim_indices: either none or a tuple that will be used to slice the confounds
                    to conform to the length of the timeseries that is passed to the GLM
                    (TRs/volumes, not seconds)

    TODO: currently the event files are basically handmade, so they artificially reflect
            the (hardcoded) trim values for the hemifield task (6 volumes up front, 1 at the end)
            instead these should be generated by the experiment code and reflect the untrimmed data,
            and then the trimming of fMRI data AND the confounds/events timeseries done in nipype (here)

    SO: for now the trim_indices only apply to the confounds (which reflect the untrimmed data)
        but in the near future they'll be applied to the events as well.
    """

    import pandas as pd
    from nipype.interfaces.base import Bunch
    import numpy as np

    # Events first
    events = pd.read_csv(events_file, sep="\t")
    if exclude is not None:  # not tested
        events.drop(exclude, axis=1, inplace=True)

    conditions = sorted(events['trial_type'].unique())
    onsets = [events['onset'][events['trial_type'] == tt].tolist() for tt in conditions]
    durations = [events['duration'][events['trial_type'] == tt].tolist() for tt in conditions]   
    if 'weight' in events.columns:
      amplitudes = [events['weight'][events['trial_type'] == tt].tolist() for tt in conditions]
    else:
      amplitudes = [np.ones(len(d)) for d in durations]

    # Confounds next
    confounds = pd.read_csv(confounds_file, sep="\t", na_values="n/a") # fmriprep confounds file
    regressor_names=['WhiteMatter', 'GlobalSignal','FramewiseDisplacement',
                        'aCompCor00',
                        'aCompCor01',
                        'aCompCor02',
                        'aCompCor03',
                        'aCompCor04',
                        'aCompCor05',
                        'X',
                        'Y',
                        'Z',
                        'RotX',
                        'RotY',
                        'RotZ']

    if trim_indices is None:
        regressors = [list(confounds[reg].fillna(0)) for reg in regressor_names]
    else:
        regressors = [list(confounds[reg].fillna(0))[slice(*trim_indices)] for reg in regressor_names]

    bunch = Bunch(conditions=conditions,
                    onsets=onsets,
                    durations=durations,
                    amplitudes=amplitudes,
                    regressor_names=regressor_names,
                    regressors=regressors)
    
    return bunch

def pickfirst(l):
    return l[0]

def sort_copes(files):
    numelements = len(files[0])
    outfiles = []
    for i in range(numelements):
        outfiles.insert(i, [])
        for j, elements in enumerate(files):
            outfiles[i].append(elements[i])
    return outfiles

def num_copes(files):
    return len(files)

def fslmaths_threshold_roi_opstring(thresh):
    return [f"-thr {thresh} -bin", f"-uthr {thresh} -bin"]

def get_files(subject_id, session, task, raw_data_dir, preprocessed_data_dir):
    """
    Given some information, retrieve all the files and metadata from a
    BIDS-formatted dataset that will be passed to the analysis pipeline.
    """
    from bids.grabbids import BIDSLayout
    
    # only the raw files have the correct metadata, eg TR, and the event files are here
    raw_layout = BIDSLayout(raw_data_dir)
    preproc_layout = BIDSLayout(preprocessed_data_dir)

    subjects = preproc_layout.get_subjects()
    assert subject_id in subjects and subject_id in raw_layout.get_subjects(), "Subject not found!"

    sessions = preproc_layout.get_sessions()
    assert session in sessions, "Session not found!"

    tasks = preproc_layout.get_tasks()
    assert task in tasks, "Task not found!"
    
    bolds = [f.filename for f in preproc_layout.get(subject=subject_id, modality='func', type='preproc', 
                              session=session, task=task, extensions=['nii.gz'])]
    masks = [f.filename for f in preproc_layout.get(subject=subject_id, modality='func', type='brainmask', 
                              session=session, task=task, extensions=['nii.gz'])]
    eventfiles =  [f.filename for f in raw_layout.get(subject=subject_id, modality="func",
                              task=task, session=session, extensions=['tsv'])]
    TRs = [raw_layout.get_metadata(f.filename)['RepetitionTime'] for f in raw_layout.get(subject=subject_id,
                              modality="func", task=task, session=session, extensions=['nii.gz'])]
    confounds = [f.filename for f in preproc_layout.get(subject=subject_id, type="confounds",
                              task=task, session=session, extensions=['tsv'])]
    print(list(zip(bolds, masks, eventfiles, TRs)))
    assert len(bolds)==len(masks)==len(eventfiles)==len(TRs)==len(confounds)>0, "Input lists are not the same length!"
    assert TRs.count(TRs[0])==len(TRs), "Not all TRs are the same!" # all runs for a particular task must have same TR
    TR = TRs[0]
    return bolds, masks, eventfiles, TR, confounds

def get_contrasts(task):
    """
    Setup the contrast structure that needs to be evaluated. This is a list of
    lists. The inner list specifies the contrasts and has the following format -
    [Name,Stat,[list of condition names],[weights on those conditions]. The
    condition names must match the `names` listed in the `subjectinfo` function
    described above.
    """
    if task == "hemi":
        cont_l = ['L>Baseline', 'T', ['L', 'R'], [1, 0]]
        cont_r = ['R>Baseline', 'T', ['L', 'R'], [0, 1]]
        cont_rl = ['R-L', 'T', ['L', 'R'], [-1, 1]]
        cont_visresp = ['Task>Baseline', 'T', ['L', 'R'], [0.5, 0.5]]
        return [cont_l, cont_r, cont_rl, cont_visresp]
    elif task == "mp":
        cont_m = ['M>Baseline', 'T', ['M', 'P'], [1, 0]]
        cont_p = ['P>Baseline', 'T', ['M', 'P'], [0, 1]]
        cont_mp = ['M-P', 'T', ['M', 'P'], [1, -1]]
        cont_visresp = ['Task>Baseline', 'T', ['M', 'P'], [0.5, 0.5]]
        return [cont_m, cont_p, cont_mp, cont_visresp]

def get_model_outputs(datasink_dir, contrasts):
    """Given the datasink directory of a glm workflow, this grabs the Level 1 and 2 results for the specified contrasts [list]."""
    import os, glob
    contents = os.listdir(datasink_dir)
    l1outdir = 'results_dir'
    l2outdir = 'stats_dir'
    #l1tstats = []
    l1copes = []
    l2outs = []
    for contrast_number in contrasts:
        if l1outdir in contents:
            l1glob = os.path.join(datasink_dir, l1outdir, '_modelestimate*')
            l1outputs = sorted(glob.glob(l1glob))
            for l1o in l1outputs:
                #l1tstats.append(os.path.join(l1o, f"results/tstat{contrast_number}.nii.gz"))
                l1copes.append(os.path.join(l1o, f"results/cope{contrast_number}.nii.gz"))
                
        if l2outdir in contents:
            l2contrastdir = os.path.join(datasink_dir, l2outdir, f"_flameo{contrast_number - 1}", "stats")
            l2outs.extend([os.path.join(l2contrastdir, x) for x in ['cope1.nii.gz', 'zstat1.nii.gz']])
        
    return l1copes, l2outs

def view_results(datasink_dir, contrast_number, anat, func, vROI=''):
    """Prints an fsleyes command to view results of L1/2 for a given contrast.
    Allows specification of anat, func, and optional other ROI image."""
    c, l2 = get_model_outputs(datasink_dir, contrast_number)
    print(f"fsleyes {anat} {func} {vROI} {' '.join(c)} {' '.join(l2)}")