def tsv2subjectinfo(events_file, confounds_file=None, exclude=None, trim_indices=None):
    """
    Function to go from events tsv + confounds tsv to subjectinfo,
    which can then be passed to model setup functions.

    events_file, confounds_file: paths to these things
    exclude: trial_types in the events_file to be ignored (does not apply to confounds)
    trim_indices: either none or a tuple that will be used to slice the confounds
                    to conform to the length of the timeseries that is passed to the GLM
                    (TRs/volumes, not seconds)

    TODO: currently the event files are basically handmade, so they artificially reflect
            the (hardcoded) trim values for the hemifield task (6 volumes up front, 1 at the end)
            instead these should be generated by the experiment code and reflect the untrimmed data,
            and then the trimming of fMRI data AND the confounds/events timeseries done in nipype (here)

    SO: for now the trim_indices only apply to the confounds (which reflect the untrimmed data)
        but in the near future they'll be applied to the events as well.
    """

    import pandas as pd
    from nipype.interfaces.base import Bunch
    import numpy as np

    # Events first
    events = pd.read_csv(events_file, sep="\t")
    if exclude is not None:  # not tested
        events.drop(exclude, axis=1, inplace=True)

    conditions = sorted(events['trial_type'].unique())
    onsets = [events['onset'][events['trial_type'] == tt].tolist() for tt in conditions]
    durations = [events['duration'][events['trial_type'] == tt].tolist() for tt in conditions]   
    if 'weight' in events.columns:
      amplitudes = [events['weight'][events['trial_type'] == tt].tolist() for tt in conditions]
    else:
      amplitudes = [np.ones(len(d)) for d in durations]

    # Confounds next
    confounds = pd.read_csv(confounds_file, sep="\t", na_values="n/a") # fmriprep confounds file
    regressor_names=['WhiteMatter', 'GlobalSignal','FramewiseDisplacement',
                        'aCompCor00',
                        'aCompCor01',
                        'aCompCor02',
                        'aCompCor03',
                        'aCompCor04',
                        'aCompCor05',
                        'X',
                        'Y',
                        'Z',
                        'RotX',
                        'RotY',
                        'RotZ']

    if trim_indices is None:
        regressors = [list(confounds[reg].fillna(0)) for reg in regressor_names]
    else:
        regressors = [list(confounds[reg].fillna(0))[slice(*trim_indices)] for reg in regressor_names]

    bunch = Bunch(conditions=conditions,
                    onsets=onsets,
                    durations=durations,
                    amplitudes=amplitudes,
                    regressor_names=regressor_names,
                    regressors=regressors)
    
    return bunch

def pickfirst(l):
    return l[0]

def sort_copes(files):
    numelements = len(files[0])
    outfiles = []
    for i in range(numelements):
        outfiles.insert(i, [])
        for j, elements in enumerate(files):
            outfiles[i].append(elements[i])
    return outfiles

def num_copes(files):
    return len(files)

def get_files(subject_id, session, task, raw_data_dir, preprocessed_data_dir):
    """
    Given some information, retrieve all the files and metadata from a
    BIDS-formatted dataset that will be passed to the analysis pipeline.
    """
    from bids.grabbids import BIDSLayout
    
    # only the raw files have the correct metadata, eg TR, and the event files are here
    raw_layout = BIDSLayout(raw_data_dir)
    preproc_layout = BIDSLayout(preprocessed_data_dir)

    subjects = preproc_layout.get_subjects()
    assert subject_id in subjects and subject_id in raw_layout.get_subjects(), "Subject not found!"

    sessions = preproc_layout.get_sessions()
    assert session in sessions, "Session not found!"

    tasks = preproc_layout.get_tasks()
    assert task in tasks, "Task not found!"
    
    bolds = [f.filename for f in preproc_layout.get(subject=subject_id, modality='func', type='preproc', 
                              session=session, task=task, extensions=['nii.gz'])]
    masks = [f.filename for f in preproc_layout.get(subject=subject_id, modality='func', type='brainmask', 
                              session=session, task=task, extensions=['nii.gz'])]
    eventfiles =  [f.filename for f in raw_layout.get(subject=subject_id, modality="func",
                              task=task, session=session, extensions=['tsv'])]
    TRs = [raw_layout.get_metadata(f.filename)['RepetitionTime'] for f in raw_layout.get(subject=subject_id,
                              modality="func", task=task, session=session, extensions=['nii.gz'])]
    confounds = [f.filename for f in preproc_layout.get(subject=subject_id, type="confounds",
                              task=task, session=session, extensions=['tsv'])]
    assert len(bolds)==len(masks)==len(eventfiles)==len(TRs)==len(confounds)>0, "Input lists are not the same length!"
    assert TRs.count(TRs[0])==len(TRs), "Not all TRs are the same!" # all runs for a particular task must have same TR

    TR = TRs[0]

    print(list(zip(bolds, masks, eventfiles, TRs)))

    return bolds, masks, eventfiles, TR, confounds

def get_hemifield_contrasts():
    """
    Setup the contrast structure that needs to be evaluated. This is a list of
    lists. The inner list specifies the contrasts and has the following format -
    [Name,Stat,[list of condition names],[weights on those conditions]. The
    condition names must match the `names` listed in the `subjectinfo` function
    described above.
    """

    cont_lr = ['L-R', 'T', ['L', 'R'], [1, -1]]
    cont_rl = ['R-L', 'T', ['L', 'R'], [-1, 1]]
    cont_visresp = ['Task>Baseline', 'T', ['L', 'R'], [0.5, 0.5]]
    return [cont_lr, cont_rl, cont_visresp]

def get_mp_contrasts():
    cont_mp = ['M-P', 'T', ['M', 'P'], [1, -1]]
    cont_pm = ['P-M', 'T', ['M', 'P'], [-1, 1]]
    cont_visresp = ['Task>Baseline', 'T', ['M', 'P'], [0.5, 0.5]]
    return [cont_mp, cont_pm, cont_visresp]

def get_files_spm(subject_id, session, task, raw_data_dir):
    """
    Given some information, retrieve all the files and metadata from a
    BIDS-formatted dataset that will be passed to an SPM-based analysis pipeline.
    """
    from bids.grabbids import BIDSLayout
    from utils import tsv2subjectinfo

    layout = BIDSLayout(raw_data_dir)

    subjects = layout.get_subjects()
    assert(subject_id in subjects and subject_id in layout.get_subjects())

    sessions = layout.get_sessions()
    assert(session in sessions)

    tasks = layout.get_tasks()
    assert(task in tasks)

    print(subjects, tasks, sessions)
    
    bolds = [f.filename for f in layout.get(subject=subject_id, modality='func', type='bold', 
                              session=session, task=task, extensions=['nii'])]

    struct = layout.get(subject=subject_id, modality='anat', session=session, type='T1w', extensions=['nii'])[0].filename

    print(struct, "\n", bolds, end="\n")

    eventfiles =  [f.filename for f in layout.get(subject=subject_id, modality="func",
                              task=task, session=session, extensions=['tsv'])]
    eventbunches = [tsv2subjectinfo(f) for f in eventfiles]
    print(eventfiles, eventbunches, sep="\n", end="\n")

    TRs = [layout.get_metadata(f.filename)['RepetitionTime'] for f in layout.get(subject=subject_id,
      type="bold", modality="func", task=task, session=session, extensions=['nii'])]
    print(TRs, end="\n")

    assert(len(bolds)==len(eventfiles)==len(TRs)>0)
    assert(TRs.count(TRs[0])==len(TRs)) # all runs for a particular task must have the same TR

    TR = TRs[0]

    print(list(zip(bolds, eventfiles, eventbunches, TRs)))

    return bolds, struct, eventbunches, TR
